# 200219 (수)

## Spark

**개요**

1. 구글의  map-reduce 방식의 출현 : https://brunch.co.kr/@nsung/29

2. 클라우딩 시스템: https://www.mrlatte.net/blog/2013/05/26/cloud-computing.html#11

3. 스파크(in-memory 방식)과 Hadoop Mapreduce(분산병렬 처리 방식) 차이

   hadoop은 디스크 기반의 mapreduce, spark는 메모리 기반의 mapreduce 방식
   → Hadoop은 mapreduce 방식으로 데이터를 분산 처리하며 여러 곳에 분산 저장된 데이터를 처리 하기 위해 mapreduce 방식으로 데이터를 처리 한다. spark 역시 mapreduce 방식의 데이터처리 구조를 지원한다. 

   즉, spark도 여러 곳에 저장된 데이터를 처리 하기 위해 mapreduce 방식으로 데이터를 처리 할 수 있다는 뜻이다. 둘의 차이는, 데이터를 메모리에 놓고 하느냐, 디스크에 놓고 하느냐로  Hadoop은 기본적으로 디스크로부터 map/reduce할 데이터를 불러오고, 처리 결과를 디스크로 쓴다. 따라서, 데이터의 읽기/쓰기 속도는 느린 반면, 디스크 용량 만큼의 데이터를 한번에 처리 할 수 있다.
   반면, spark는 메모리로부터 map/reduce할 데이터를 불러오고, 처리 결과를 메모리로 쓴다. 따라서, 데이터의 읽기/쓰기 속도는 빠른 반면, 메모리 용량만큼의 데이터만 한번에 처리 할 수 있다. 보다 정확히 표현하면, 메모리 용량보다 큰 데이터를 처리 할 때는 처리 이외의 메모리 내 데이터 교체라던가, 작업 과정 저장, 컨텍스트 스위칭 등과 같은 류의 과부하가 걸릴 수도 있다. 
   결론은, spark나 hadoop이나 모두 mapreduce 방식을 지원하지만 hadoop은 디스크 기반의 mapreduce 인것이고, spark는 메모리 기반의 mapreduce 인 것이다. 메모리가 커버 가능한 만큼의 데이터라면, 메모리 기반이 유리 할 것이고, 메모리 용량 이상의 데이터라면 크면 클수록, 디스크 기반이 유리하다. 또한, 메모리 기반이 속도가 장점인만큼, 기계학습이나 마이닝과 같은 반복 작업이 많을 수록 메모리 기반이 유리하다. (단, 일정 용량 이하의 데이터인 경우에 한함)





