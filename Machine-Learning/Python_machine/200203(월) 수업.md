# 200203(월) 수업

## 텍스트 데이터

### 문자열 데이터

* **범주형 데이터**

고정된 목록으로 구성

* **범주에 의미를 연결시킬 수 있는 임의의 문자열**

범주형 변수로 인코딩하려면 가장 보편적인 값을 선택하거나 포용 범주 정의가 최선

전처리 중 수작업이 많이 필요하며 자동화 어려움

* **구조화된 문자열 데이터**

미리 정의된 범주에 속하지 않지만 직접 입력한 값들이 주소나 장소, 날짜, 식별번호 처럼 일정한 구조 가짐

분석하기 매우 어렵고ㅡ 처리 방법이 문맥이나 분야에 따라 매우 다르다.

* **텍스트 데이터**

자유로운 형태의 절과 문장으로 구성

예시로 트윗, 채팅, 호텔 리뷰, 위키백과 등

> 데이터셋 = 말뭉치(corpus)
>
> 하나의 텍스트를 의미하는 각 데이터 포인트 = 문서(document)
>
> ==> 정보 검색(IR;information) 과 자연어 처리(NLP; natural language processing) 공동체에서 유래



----

##### 텍스트 데이터는 머신러닝 모델이 다룰 수 있는 형태가 아니므로 텍스트의 문자열 표현을 머신러닝 알고리즘에 적용할 수 있도록 수치 표현으로 바꿔야 한다.

##### 

### 텍스트 데이터_BOW

* BOW (bag of words)

: 문서가 가지는 모든 단어를 문맥이나 순서를 무시하고 일괄적으로 단어에 대해 빈도 값을 부여해 피처 값을 추출하는 모델

: 구조와 상관없이 단어의 출현 횟수만 세기 때문에 텍스트를 담는 가방으로 생각할 수 있음



* BOW 단계

>1. 토큰화(tokenization): 각 문서를 문서에 포함된 단어(토큰)로 나눈다. ex) 공백, 구두점 등 기준
>
>2. 어휘 사전 구축: 모든 문서에 나타난 모든 단어의 어휘를 모으고 번호 매김 (알파벳 순서)
>
>3. 인코딩: 어휘 사전의 단어가 문서마다 몇 번이나 나타나는지를 헤아림
>
>   * 희소행렬(sparse matrix): 
>
>     밀집행렬(dense matrix):







희소행렬 <-> 밀집행렬

희소행렬(sparse matrix): 

밀집행렬(dense matrix):



한번에 들어가는 아디''



gensim